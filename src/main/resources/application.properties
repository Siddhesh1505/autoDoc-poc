spring.application.name=autodoc

# --- Spring AI & Ollama Configuration ---
spring.ai.ollama.base-url=http://localhost:11434
# Use llama3 for general docs or codellama for better code understanding
spring.ai.ollama.chat.options.model=llama3

# --- LLM Performance Settings ---
# Since code analysis is heavy, we increase the timeout
spring.ai.ollama.chat.options.num-predict=4096
spring.ai.ollama.chat.options.temperature=0.3

# --- Server Configuration ---
server.port=8080

# --- Optional: Git Auth (if using private repos) ---
# git.username=your_username
# git.token=your_pat_token